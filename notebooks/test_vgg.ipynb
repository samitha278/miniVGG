{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b006e5",
   "metadata": {},
   "source": [
    "# Trained in Rtx 4080 16GB, max iter 200000, LR Schedule, AMP(bfloat16) + torch.compile(), Imagenet100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2151c100",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvgg_v3\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m minVGG,Config\n\u001b[1;32m      3\u001b[0m config \u001b[38;5;241m=\u001b[39m Config()\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m minVGG(config)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.models.vgg_v3 import minVGG,Config\n",
    "\n",
    "config = Config()\n",
    "model = minVGG(config)\n",
    "\n",
    "print(sum([p.numel() for p in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd97a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sz = \"85M\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"/home/samitha/Projects/miniVGG/log/log.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "streams = {}\n",
    "for line in lines:\n",
    "    step, stream, val = line.strip().split()\n",
    "    if stream not in streams:\n",
    "        streams[stream] = {}\n",
    "    streams[stream][int(step)] = float(val)\n",
    "\n",
    "streams_xy = {}\n",
    "for k, v in streams.items():\n",
    "    xy = sorted(list(v.items()))\n",
    "    streams_xy[k] = list(zip(*xy))\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# losses: both train and val\n",
    "plt.subplot(121)\n",
    "xs, ys = streams_xy[\"train\"] # training loss\n",
    "ys = np.array(ys)\n",
    "plt.plot(xs, ys, label=f'ViT-B ({sz}) train loss')\n",
    "print(\"Min Train Loss:\", min(ys))\n",
    "xs, ys = streams_xy[\"val\"] # validation loss\n",
    "plt.plot(xs, ys, label=f'ViT-B ({sz}) val loss')\n",
    "\n",
    "\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss - log\")\n",
    "plt.yscale('log')\n",
    "# plt.ylim(top=5.0)\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "print(\"Min Validation Loss:\", min(ys))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
