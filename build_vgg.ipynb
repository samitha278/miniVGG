{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMafCh0gTPbfbMZ4gGBuLV+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samitha278/miniVGG/blob/main/build_vgg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "1BohYIwpIVZ9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Convolution function"
      ],
      "metadata": {
        "id": "2xiuBEVgYqg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Convolution(image,kernel):\n",
        "\n",
        "  x,y = image.shape\n",
        "\n",
        "  a,b = kernel.shape\n",
        "\n",
        "  feature_map = []\n",
        "\n",
        "  for i in range(y-b):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    for j in range(x-a):\n",
        "\n",
        "      temp = (image[i:i+b,j:j+a] * kernel).sum(dim=(0,1))\n",
        "\n",
        "      row.append(temp.item())\n",
        "\n",
        "    feature_map.append(row)\n",
        "\n",
        "  return torch.tensor(feature_map)"
      ],
      "metadata": {
        "id": "IEuWS_j6Id_A"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.randn((32,32))\n",
        "kernel = torch.ones((3,3)) * (9**-1)\n",
        "\n",
        "\n",
        "feature_map = Convolution(image,kernel)\n"
      ],
      "metadata": {
        "id": "aprY8O8mK08d"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_map.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rPfuwUIQBgB",
        "outputId": "80f78a8c-5ad6-4d8e-fa23-1a25e9175ea0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([29, 29])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolution with stride"
      ],
      "metadata": {
        "id": "vHxs061xYu3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Convolution(image,kernel,stride=(1,1)):\n",
        "\n",
        "  x,y = image.shape\n",
        "  a,b = kernel.shape\n",
        "\n",
        "  r,c = stride\n",
        "\n",
        "  feature_map = []\n",
        "\n",
        "  for i in range(0,y-b,c):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    for j in range(0,x-a,r):\n",
        "\n",
        "      temp = (image[i:i+b,j:j+a] * kernel).sum(dim=(0,1))\n",
        "\n",
        "      row.append(temp.item())\n",
        "\n",
        "    feature_map.append(row)\n",
        "\n",
        "  return torch.tensor(feature_map)"
      ],
      "metadata": {
        "id": "xQbUppBMRAlH"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.randn((32,32))\n",
        "kernel = torch.ones((3,3)) * (9**-1)\n",
        "\n",
        "\n",
        "feature_map = Convolution(image,kernel,(2,1))      # 2: aloge side rows , 1: along side columns\n"
      ],
      "metadata": {
        "id": "8gnkQhdwdkx-"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_map.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHRzV0k5doNH",
        "outputId": "ca58a535-9e5a-4c4e-b550-d630f482e70c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([29, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Padding"
      ],
      "metadata": {
        "id": "R4eAXkpueKTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_padding(image, padding):\n",
        "\n",
        "\n",
        "\n",
        "  r,c = padding\n",
        "\n",
        "  if r>0 :\n",
        "    rows = torch.zeros((r,image.shape[1]))\n",
        "\n",
        "    image = torch.cat((rows , image , rows),dim=0)\n",
        "\n",
        "  if c>0:\n",
        "\n",
        "    columns = torch.zeros((c,image.shape[0]))\n",
        "\n",
        "    image = torch.cat((columns , image.T , columns),dim=0)\n",
        "\n",
        "\n",
        "  return image.T\n",
        "\n"
      ],
      "metadata": {
        "id": "kqn-dKa9L0vj"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_padding(torch.randn(2,2),(2,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEZZngmkWXtv",
        "outputId": "164b5f35-a1c5-4730-d00a-e5fd23ddd641"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.8457, -0.2871,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  1.2280,  0.6533,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Convolution(image,kernel,stride=(1,1),padding = (0,0)):\n",
        "\n",
        "\n",
        "  a,b = kernel.shape\n",
        "\n",
        "  r,c = stride\n",
        "\n",
        "  image_pd = image if padding==(0,0) else add_padding(image,padding)\n",
        "\n",
        "  feature_map = []\n",
        "\n",
        "  x,y = image_pd.shape\n",
        "\n",
        "  for i in range(0,y-b,c):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    for j in range(0,x-a,r):\n",
        "\n",
        "      temp = (image_pd[i:i+b,j:j+a] * kernel).sum(dim=(0,1))\n",
        "\n",
        "      row.append(temp.item())\n",
        "\n",
        "    feature_map.append(row)\n",
        "\n",
        "  return torch.tensor(feature_map)"
      ],
      "metadata": {
        "id": "8lou7779dt22"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.randn((32,32))\n",
        "kernel = torch.ones((3,3)) * (9**-1)\n",
        "\n",
        "\n",
        "feature_map = Convolution(image,kernel, padding=(2,2))\n"
      ],
      "metadata": {
        "id": "-isnZot9ZnKI"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_map.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HJ2ScO0Z0fG",
        "outputId": "bccd0983-968a-43c7-a365-4bd7a8218878"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([33, 33])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple adding pad func"
      ],
      "metadata": {
        "id": "JgaVXqF6bDfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_padding2(matrix,padding):\n",
        "\n",
        "  n,m = matrix.shape\n",
        "\n",
        "  r,c = padding\n",
        "\n",
        "  padded_matrix = torch.zeros((n+r*2,m+c*2))\n",
        "\n",
        "  padded_matrix[r:r+n,c:c+m] = matrix\n",
        "\n",
        "  return padded_matrix"
      ],
      "metadata": {
        "id": "jI4qh6KpZ2kJ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_padding2(torch.randn(2,2),(2,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaRBYT3Vcs_7",
        "outputId": "ab0534bb-654f-42a9-fd03-6a05de6a6f3b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000, -0.9070, -0.0018,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.8128, -1.2010,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding Dialation"
      ],
      "metadata": {
        "id": "zsARmMMPdaZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Convolution(image,kernel,stride=(1,1),padding = (0,0),dilation=(1,1)):\n",
        "\n",
        "\n",
        "  a,b = kernel.shape\n",
        "\n",
        "  r,c = stride\n",
        "\n",
        "  d1,d2 = dilation\n",
        "\n",
        "  image_pd = image if padding==(0,0) else add_padding2(image,padding)\n",
        "\n",
        "  feature_map = []\n",
        "\n",
        "  x,y = image_pd.shape\n",
        "\n",
        "\n",
        "  for i in range(0,x-a*d1+1,r):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    for j in range(0,y-b*d2+1,c):\n",
        "\n",
        "      temp = (image_pd[i:i+a*d1:d1,j:j+b*d2:d2] * kernel).sum(dim=(0,1))\n",
        "\n",
        "      row.append(temp.item())\n",
        "\n",
        "    feature_map.append(row)\n",
        "\n",
        "  return torch.tensor(feature_map)"
      ],
      "metadata": {
        "id": "ag8GkDJzc-Vw"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.randn((32,32))\n",
        "kernel = torch.ones((3,3)) * (9**-1)\n",
        "\n",
        "\n",
        "feature_map = Convolution(image,kernel,(2,2),(2,2) ,dilation=(2,2))"
      ],
      "metadata": {
        "id": "_HIaqGa0yArI"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_map.shape"
      ],
      "metadata": {
        "id": "3bIGNsuTyIbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb67d698-4c11-49a1-affd-e9c76217666e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test : comparision with pytorch conv2d"
      ],
      "metadata": {
        "id": "2PSgSdooBcum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.randn((32,32))\n",
        "kernel = torch.ones((3,3)) * (9**-1)\n",
        "\n",
        "out_custom = Convolution(image, kernel, stride=(2,2), padding=(1,1), dilation=(2,2))\n",
        "\n",
        "\n",
        "img4d = image.unsqueeze(0).unsqueeze(0)       # (1,1,4,4)\n",
        "kernel4d = kernel.unsqueeze(0).unsqueeze(0) # (1,1,2,2)\n",
        "\n",
        "out_torch = F.conv2d(img4d, kernel4d, stride=(2,2), padding=(1,1), dilation=(2,2))\n",
        "\n",
        "print(\"Custom:\\n\", out_custom.shape)\n",
        "print(\"Torch:\\n\", out_torch.squeeze().shape)\n",
        "print(\"Match? ->\", torch.allclose(out_custom,out_torch.squeeze()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rxzc5-Ws5VR",
        "outputId": "3c53bd3f-db83-4bbb-9fb7-2add13da2202"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom:\n",
            " torch.Size([15, 15])\n",
            "Torch:\n",
            " torch.Size([15, 15])\n",
            "Match? -> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All at once"
      ],
      "metadata": {
        "id": "iBcW_6DpIrsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_padding2(matrix,padding):\n",
        "  n,m = matrix.shape\n",
        "  r,c = padding\n",
        "\n",
        "  padded_matrix = torch.zeros((n+r*2,m+c*2))\n",
        "  padded_matrix[r:r+n,c:c+m] = matrix\n",
        "\n",
        "  return padded_matrix"
      ],
      "metadata": {
        "id": "HXDBUD8lI3lh"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Convolution(image, kernel, stride=(1,1), padding=(0,0), dilation=(1,1)):\n",
        "    a, b = kernel.shape\n",
        "    r, c = stride\n",
        "    d1, d2 = dilation\n",
        "\n",
        "    image_pd = image if padding == (0,0) else add_padding2(image, padding)\n",
        "    feature_map = []\n",
        "    x, y = image_pd.shape\n",
        "\n",
        "    for i in range(0, x - a*d1 + 1, r):\n",
        "        row = []\n",
        "        for j in range(0, y - b*d2 + 1, c):\n",
        "\n",
        "            temp = (image_pd[i:i+a*d1:d1, j:j+b*d2:d2] * kernel).sum(dim=(0,1))\n",
        "            row.append(temp.item())\n",
        "        feature_map.append(row)\n",
        "\n",
        "    return torch.tensor(feature_map)"
      ],
      "metadata": {
        "id": "K1ajUxKNBmxD"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.manual_seed(220064)\n",
        "image = torch.randn((32,32))\n",
        "kernel = torch.ones((3,3)) * (9**-1)\n",
        "\n",
        "out_custom = Convolution(image, kernel, stride=(2,2), padding=(1,1), dilation=(2,2))\n",
        "\n",
        "\n",
        "img4d = image.unsqueeze(0).unsqueeze(0)       # (1,1,4,4)\n",
        "kernel4d = kernel.unsqueeze(0).unsqueeze(0) # (1,1,2,2)\n",
        "\n",
        "out_torch = F.conv2d(img4d, kernel4d, stride=(2,2), padding=(1,1), dilation=(2,2))\n",
        "\n",
        "print(\"Custom:\\n\", out_custom.shape)\n",
        "print(\"Torch:\\n\", out_torch.squeeze().shape)\n",
        "print(\"Match? ->\", torch.allclose(out_custom,out_torch.squeeze()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwys6oPrI6YL",
        "outputId": "a8109b09-e296-46d4-d962-1bb3224522c9"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom:\n",
            " torch.Size([15, 15])\n",
            "Torch:\n",
            " torch.Size([15, 15])\n",
            "Match? -> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test nn.Conv2d"
      ],
      "metadata": {
        "id": "sMbL7SCfLKbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(200)\n",
        "\n",
        "c_l = nn.Conv2d(2,4,3)      # in channel = 2, out channel = 4, kernel size = 3x3\n",
        "\n",
        "\n",
        "sd = c_l.__dict__['_parameters']\n",
        "wei = sd['weight']\n",
        "bias = sd['bias']\n",
        "\n",
        "img = torch.randn(2,12,12)\n"
      ],
      "metadata": {
        "id": "7JuIATtbLBP5"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for outout channel 1\n",
        "out = Convolution(img[0],wei[0,0]) + Convolution(img[1],wei[0,1]) + bias[0]"
      ],
      "metadata": {
        "id": "HVFT9JngLuVx"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_real = c_l(img)[0]"
      ],
      "metadata": {
        "id": "OAQ5iR73LUR1"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.allclose(out_real,out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQDfyyqGNggE",
        "outputId": "f624b26f-e996-41e7-d9ee-aa3cbeb2299d"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX5ZN2NwQm6x",
        "outputId": "aca9c87d-078a-45b9-be78-7e935334a41b"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1716, -0.8489,  0.0087,  0.3687,  0.0612, -0.4664, -0.0916,  0.3448,\n",
              "         -0.3278,  0.4495],\n",
              "        [-0.9561,  0.1782,  0.3831, -0.2250, -0.4388, -0.5568, -0.3419,  0.2183,\n",
              "          0.0076, -0.6042],\n",
              "        [ 0.0471, -0.4671, -0.2238, -0.1945,  0.2181, -0.4026, -0.5394, -0.6788,\n",
              "         -0.5775, -0.8300],\n",
              "        [-0.1201,  0.0371, -0.3132, -0.2208, -0.2247, -0.3121,  0.1181, -0.3183,\n",
              "          0.2815, -1.5969],\n",
              "        [ 0.3042,  0.3495, -0.1749,  0.1566, -1.6928, -0.1662,  0.3522, -0.1735,\n",
              "         -0.7710, -0.8561],\n",
              "        [ 0.1167,  0.8531,  0.7492,  0.0081, -0.7360, -0.0125, -0.1202, -1.4806,\n",
              "          0.8252,  0.3005],\n",
              "        [-0.3631, -0.4048,  1.2756,  0.3087, -1.7028,  0.7630,  0.2855, -1.1258,\n",
              "          0.5164,  0.3389],\n",
              "        [-0.2170,  0.4665, -0.0310,  0.3007,  0.1645, -0.0165, -0.6288, -0.9614,\n",
              "         -0.2822,  0.3014],\n",
              "        [-1.0514, -0.2228, -0.3419,  0.8720, -0.4499,  0.1352, -0.1190, -0.4014,\n",
              "          0.8269,  0.5460],\n",
              "        [ 0.5875,  0.6329, -0.9254, -1.2093, -0.4766, -0.2230,  0.2021, -0.4626,\n",
              "         -0.4579, -0.0720]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conv2d Class"
      ],
      "metadata": {
        "id": "slGCyBanLXwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class conv2d(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.kernel\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self,matrix,kernel,stride=(1,1),padding=(0,0),dilation=(1,1)):\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iEg1eSdPJFIP"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z7nsaCzUQoLR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}