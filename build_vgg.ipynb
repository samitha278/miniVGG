{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmmmpynsjBBtLVQ1P+7lfx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samitha278/miniVGG/blob/main/build_vgg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "1BohYIwpIVZ9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Convolution function"
      ],
      "metadata": {
        "id": "2xiuBEVgYqg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Convolution(image,kernel):\n",
        "\n",
        "  x,y = image.shape\n",
        "\n",
        "  a,b = kernel.shape\n",
        "\n",
        "  feature_map = []\n",
        "\n",
        "  for i in range(y-b):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    for j in range(x-a):\n",
        "\n",
        "      temp = (image[i:i+b,j:j+a] * kernel).sum(dim=(0,1))\n",
        "\n",
        "      row.append(temp.item())\n",
        "\n",
        "    feature_map.append(row)\n",
        "\n",
        "  return torch.tensor(feature_map)"
      ],
      "metadata": {
        "id": "IEuWS_j6Id_A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.randn((32,32))\n",
        "kernel = torch.ones((3,3)) * (9**-1)\n",
        "\n",
        "\n",
        "feature_map = Convolution(image,kernel)\n"
      ],
      "metadata": {
        "id": "aprY8O8mK08d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_map.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rPfuwUIQBgB",
        "outputId": "753ba78f-a0f8-4960-b543-7e32b6acebe2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([29, 29])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolution with stride"
      ],
      "metadata": {
        "id": "vHxs061xYu3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Convolution(image,kernel,stride=(1,1)):\n",
        "\n",
        "  x,y = image.shape\n",
        "  a,b = kernel.shape\n",
        "\n",
        "  r,c = stride\n",
        "\n",
        "  feature_map = []\n",
        "\n",
        "  for i in range(0,y-b,c):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    for j in range(0,x-a,r):\n",
        "\n",
        "      temp = (image[i:i+b,j:j+a] * kernel).sum(dim=(0,1))\n",
        "\n",
        "      row.append(temp.item())\n",
        "\n",
        "    feature_map.append(row)\n",
        "\n",
        "  return torch.tensor(feature_map)"
      ],
      "metadata": {
        "id": "xQbUppBMRAlH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.randn((32,32))\n",
        "kernel = torch.ones((3,3)) * (9**-1)\n",
        "\n",
        "\n",
        "feature_map = Convolution(image,kernel,(2,1))      # 2: aloge side rows , 1: along side columns\n"
      ],
      "metadata": {
        "id": "8gnkQhdwdkx-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_map.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHRzV0k5doNH",
        "outputId": "aebb992e-4eb9-4aeb-f47c-7f59fccac492"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([29, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Padding"
      ],
      "metadata": {
        "id": "R4eAXkpueKTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_padding(image, padding):\n",
        "\n",
        "\n",
        "\n",
        "  r,c = padding\n",
        "\n",
        "  if r>0 :\n",
        "    rows = torch.zeros((r,image.shape[1]))\n",
        "\n",
        "    image = torch.cat((rows , image , rows),dim=0)\n",
        "\n",
        "  if c>0:\n",
        "\n",
        "    columns = torch.zeros((c,image.shape[0]))\n",
        "\n",
        "    image = torch.cat((columns , image.T , columns),dim=0)\n",
        "\n",
        "\n",
        "  return image.T\n",
        "\n"
      ],
      "metadata": {
        "id": "kqn-dKa9L0vj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_padding(torch.randn(2,2),(2,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEZZngmkWXtv",
        "outputId": "eecdec1b-ede1-43d7-8dd3-0c15e445e70c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000, -0.8560,  0.8522,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000, -0.1153,  0.8907,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Convolution(image,kernel,stride=(1,1),padding = (0,0)):\n",
        "\n",
        "\n",
        "  a,b = kernel.shape\n",
        "\n",
        "  r,c = stride\n",
        "\n",
        "  image_pd = image if padding==(0,0) else add_padding(image,padding)\n",
        "\n",
        "  feature_map = []\n",
        "\n",
        "  x,y = image_pd.shape\n",
        "\n",
        "  for i in range(0,y-b,c):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    for j in range(0,x-a,r):\n",
        "\n",
        "      temp = (image_pd[i:i+b,j:j+a] * kernel).sum(dim=(0,1))\n",
        "\n",
        "      row.append(temp.item())\n",
        "\n",
        "    feature_map.append(row)\n",
        "\n",
        "  return torch.tensor(feature_map)"
      ],
      "metadata": {
        "id": "8lou7779dt22"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.randn((32,32))\n",
        "kernel = torch.ones((3,3)) * (9**-1)\n",
        "\n",
        "\n",
        "feature_map = Convolution(image,kernel, padding=(2,2))\n"
      ],
      "metadata": {
        "id": "-isnZot9ZnKI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_map.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HJ2ScO0Z0fG",
        "outputId": "5098b56e-eafa-474e-c33c-6f6f84bcde8c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([33, 33])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple adding pad func"
      ],
      "metadata": {
        "id": "JgaVXqF6bDfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_padding2(matrix,padding):\n",
        "\n",
        "  n,m = matrix.shape\n",
        "\n",
        "  r,c = padding\n",
        "\n",
        "  padded_matrix = torch.zeros((n+r*2,m+c*2))\n",
        "\n",
        "  padded_matrix[r:r+n,c:c+m] = matrix\n",
        "\n",
        "  return padded_matrix"
      ],
      "metadata": {
        "id": "jI4qh6KpZ2kJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_padding2(torch.randn(2,2),(2,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaRBYT3Vcs_7",
        "outputId": "101178bf-1c2b-49ad-d2ea-94e2af5b44eb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000, -0.5225, -0.3538,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.3305, -0.8458,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding Dialation"
      ],
      "metadata": {
        "id": "zsARmMMPdaZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Convolution(image,kernel,stride=(1,1),padding = (0,0),dilation=(1,1)):\n",
        "\n",
        "\n",
        "  a,b = kernel.shape\n",
        "\n",
        "  r,c = stride\n",
        "\n",
        "  d1,d2 = dilation\n",
        "\n",
        "  image_pd = image if padding==(0,0) else add_padding2(image,padding)\n",
        "\n",
        "  feature_map = []\n",
        "\n",
        "  x,y = image_pd.shape\n",
        "\n",
        "\n",
        "  for i in range(0,x-a*d1+1,r):\n",
        "\n",
        "    row = []\n",
        "\n",
        "    for j in range(0,y-b*d2+1,c):\n",
        "\n",
        "      temp = (image_pd[i:i+a*d1:d1,j:j+b*d2:d2] * kernel).sum(dim=(0,1))\n",
        "\n",
        "      row.append(temp.item())\n",
        "\n",
        "    feature_map.append(row)\n",
        "\n",
        "  return torch.tensor(feature_map)"
      ],
      "metadata": {
        "id": "ag8GkDJzc-Vw"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.randn((32,32))\n",
        "kernel = torch.ones((3,3)) * (9**-1)\n",
        "\n",
        "\n",
        "feature_map = Convolution(image,kernel,(2,2),(2,2) ,dilation=(2,2))"
      ],
      "metadata": {
        "id": "_HIaqGa0yArI"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_map.shape"
      ],
      "metadata": {
        "id": "3bIGNsuTyIbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2738f389-e1fa-4440-e642-3ffe6f59bee2"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test : comparision with pytorch conv2d"
      ],
      "metadata": {
        "id": "2PSgSdooBcum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = torch.randn((32,32))\n",
        "kernel = torch.ones((3,3)) * (9**-1)\n",
        "\n",
        "out_custom = Convolution(image, kernel, stride=(2,2), padding=(1,1), dilation=(2,2))\n",
        "\n",
        "\n",
        "img4d = image.unsqueeze(0).unsqueeze(0)       # (1,1,4,4)\n",
        "kernel4d = kernel.unsqueeze(0).unsqueeze(0) # (1,1,2,2)\n",
        "\n",
        "out_torch = F.conv2d(img4d, kernel4d, stride=(2,2), padding=(1,1), dilation=(2,2))\n",
        "\n",
        "print(\"Custom:\\n\", out_custom.shape)\n",
        "print(\"Torch:\\n\", out_torch.squeeze().shape)\n",
        "print(\"Match? ->\", torch.allclose(out_custom,out_torch.squeeze()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rxzc5-Ws5VR",
        "outputId": "0b3b9f27-6847-4056-bf39-04de6f1d04be"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom:\n",
            " torch.Size([15, 15])\n",
            "Torch:\n",
            " torch.Size([15, 15])\n",
            "Match? -> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All at once"
      ],
      "metadata": {
        "id": "iBcW_6DpIrsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_padding2(matrix,padding):\n",
        "  n,m = matrix.shape\n",
        "  r,c = padding\n",
        "\n",
        "  padded_matrix = torch.zeros((n+r*2,m+c*2))\n",
        "  padded_matrix[r:r+n,c:c+m] = matrix\n",
        "\n",
        "  return padded_matrix"
      ],
      "metadata": {
        "id": "HXDBUD8lI3lh"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Convolution(image, kernel, stride=(1,1), padding=(0,0), dilation=(1,1)):\n",
        "    a, b = kernel.shape\n",
        "    r, c = stride\n",
        "    d1, d2 = dilation\n",
        "\n",
        "    image_pd = image if padding == (0,0) else add_padding2(image, padding)\n",
        "    feature_map = []\n",
        "    x, y = image_pd.shape\n",
        "\n",
        "    for i in range(0, x - a*d1 + 1, r):\n",
        "        row = []\n",
        "        for j in range(0, y - b*d2 + 1, c):\n",
        "\n",
        "            temp = (image_pd[i:i+a*d1:d1, j:j+b*d2:d2] * kernel).sum(dim=(0,1))\n",
        "            row.append(temp.item())\n",
        "        feature_map.append(row)\n",
        "\n",
        "    return torch.tensor(feature_map)"
      ],
      "metadata": {
        "id": "K1ajUxKNBmxD"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.manual_seed(220064)\n",
        "image = torch.randn((32,32))\n",
        "kernel = torch.ones((3,3)) * (9**-1)\n",
        "\n",
        "out_custom = Convolution(image, kernel, stride=(2,2), padding=(1,1), dilation=(2,2))\n",
        "\n",
        "\n",
        "img4d = image.unsqueeze(0).unsqueeze(0)       # (1,1,4,4)\n",
        "kernel4d = kernel.unsqueeze(0).unsqueeze(0) # (1,1,2,2)\n",
        "\n",
        "out_torch = F.conv2d(img4d, kernel4d, stride=(2,2), padding=(1,1), dilation=(2,2))\n",
        "\n",
        "print(\"Custom:\\n\", out_custom.shape)\n",
        "print(\"Torch:\\n\", out_torch.squeeze().shape)\n",
        "print(\"Match? ->\", torch.allclose(out_custom,out_torch.squeeze()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwys6oPrI6YL",
        "outputId": "5f700101-cf13-40c6-e613-352b4c6d16f3"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom:\n",
            " torch.Size([15, 15])\n",
            "Torch:\n",
            " torch.Size([15, 15])\n",
            "Match? -> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iEg1eSdPJFIP"
      },
      "execution_count": 129,
      "outputs": []
    }
  ]
}